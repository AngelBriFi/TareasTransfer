{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "aJvdRW_asVWr",
        "CLWCrmnpse89"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Maestría en Inteligencia Artificial Aplicada**\n",
        "\n",
        "## **Curso: Inteligencia Artificial y Aprendizaje Automático**\n",
        "\n",
        "Tecnológico de Monterrey\n",
        "\n",
        "Prof Luis Eduardo Falcón Morales\n",
        "\n",
        "**Actividad de la Semana 5**\n",
        "\n",
        "### **Modelos basados en Árboles**\n"
      ],
      "metadata": {
        "id": "jGyrTCouSScG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Nombres y matrículas de los integrantes del Equipo:**\n",
        "\n",
        "*   Nombre y matrícula\n",
        "*   Nombre y matrícula\n",
        "*   Nombre y matrícula\n",
        "\n"
      ],
      "metadata": {
        "id": "SxfoKPliSz3H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PARTE - 1 - Bosque Aleatorio (Random Forest) - Clasificación**"
      ],
      "metadata": {
        "id": "aJvdRW_asVWr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oLDgzdzq5szg"
      },
      "outputs": [],
      "source": [
        "# Importamos lo necesario para la actividad\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV, learning_curve, cross_val_score, StratifiedKFold\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc, precision_recall_curve, average_precision_score\n",
        "from sklearn.metrics import make_scorer, recall_score, accuracy_score, precision_score, f1_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.dummy import DummyClassifier\n",
        "\n",
        "from imblearn.pipeline import Pipeline  # Observa que usamos imblearn.Pipeline en lugar de sklearn\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "\n",
        "# Semilla para reproducibilidad\n",
        "np.random.seed(17)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Para esta actividad vamos a generar datos sintéticos para un problema de\n",
        "# clasificación binario utilizando \"make_classification\" de sklearn.\n",
        "\n",
        "# Recuerda consultar la documentación para mayor información:\n",
        "# https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html\n",
        "\n",
        "# Utilizaremos los siguientes calores de los hiperparámetros de make_classification:\n",
        "# - n_samples: número de muestras (10,000)\n",
        "# - n_features: número total de características (20)\n",
        "# - n_informative: número de características informativas (14)\n",
        "# - n_redundant: número de características redundantes (6) .. .incluímos algunas redundantes\n",
        "# - weights: pesos para las clases [0,1]-->[0.9, 0.1] para conseguir el desbalance 90%-10%\n",
        "# - class_sep: separación entre clases (mayor valor --> clases más separables y menos complejo)\n",
        "# - flip_y: fracción de ejemplos cuya clase se cambia aleatoriamente (ruido), para hacerlo más complejo\n",
        "# - random_state: semilla para reproducibilidad\n",
        "\n",
        "X, y = make_classification(\n",
        "    n_samples=10_000,          # 10,000 registros\n",
        "    n_features=20,             # 20 factores en total\n",
        "    n_informative=14,          # 14 factores informativos\n",
        "    n_redundant=6,             # 6 factores redundantes (dependientes)\n",
        "    weights=[0.9, 0.1],        # Desbalance de clases: 90% clase 0, 10% clase 1\n",
        "    class_sep=1.0,             # Separación entre clases\n",
        "    n_classes=2,               # Dos clases\n",
        "    n_clusters_per_class=1,    # Si queremos agregar complejidad adicional > 1\n",
        "    flip_y=0.03,               # Añadir algo de ruido. default 0.01\n",
        "    random_state=17,\n",
        ")"
      ],
      "metadata": {
        "id": "Gv02e0nI5ylj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Por el momento generaremos un conjunto de dato que supondremos ya\n",
        "# están escalados y todos las variables son numéricas, para concentrarnos\n",
        "# en el modelo de Bosque Aleatrorio.\n",
        "\n",
        "# Escalamos las características para que estén en el mismo rango:\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Creamos un DataFrame para su mejor manejo\n",
        "feature_names = [f'feature_{i+1}' for i in range(20)]\n",
        "df = pd.DataFrame(X_scaled, columns=feature_names)\n",
        "df['target'] = y\n",
        "\n",
        "print(f\"Total de registros generados: {len(df)}\")\n",
        "print(f\"Distribución de clases: {df['target'].value_counts(normalize=True).mul(100).round(1).astype(str) + '%'}\")\n",
        "print(f\"Cantidad de features: {len(feature_names)}\")"
      ],
      "metadata": {
        "id": "QMhcUInh78C1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(df).describe().T   # Observamos que todos los factores varían en el mismo\n",
        "                                # rango de aproximadamente -4 y 4."
      ],
      "metadata": {
        "id": "jkmFcmS-7rnP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Separamos las variables de entrada y la variable objetivo de salida:\n",
        "X = df.drop('target', axis=1).values\n",
        "y = df['target'].values\n",
        "\n",
        "# Dividir el conjunto de datos en entrenamiento (80%) y prueba (20%)\n",
        "# Como vamos a utilizar Validación Cruzada, haremos la partición\n",
        "# en Entrenamiento y Prueba.\n",
        "# Además usamos s\"tratify\" para mantener la proporción de clases en la partición.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=17, stratify=y)\n",
        "\n",
        "print(f\"Tamaño del conjunto de entrenamiento: {X_train.shape[0]} muestras\")\n",
        "print(f\"Tamaño del conjunto de prueba: {X_test.shape[0]} muestras\")"
      ],
      "metadata": {
        "id": "fIhubZHG8a-Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hagamos esta partición temporal para tener un valor aproximado del desempeño\n",
        "# mínimo que alcanzará nuestro modelo más simple.\n",
        "Xt, Xv, yt, yv = train_test_split(X_train, y_train, test_size=0.2, random_state=17, stratify=y_train)\n",
        "\n",
        "estrategias = ['most_frequent','prior','stratified','uniform']\n",
        "\n",
        "for estrategia in estrategias:\n",
        "  dummy_clf = DummyClassifier(strategy=estrategia, random_state=17)\n",
        "  dummy_clf.fit(Xt, yt)\n",
        "  y_pred = dummy_clf.predict(Xv)\n",
        "\n",
        "  # Tabla para almacenar resultados\n",
        "  results = []\n",
        "\n",
        "  # \"pos_label\" indica la clase con respecto a la cual evaluar cada métrica.\n",
        "  acc = accuracy_score(yv, y_pred)\n",
        "  rec = recall_score(yv, y_pred, pos_label=1)\n",
        "  prec = precision_score(yv, y_pred, pos_label=1)\n",
        "  f1_sc = f1_score(yv, y_pred, pos_label=1)\n",
        "\n",
        "  results.append({'Accuracy': acc,\n",
        "                'Recall': rec,\n",
        "                'Precision': prec,\n",
        "                'F1 Score': f1_sc\n",
        "                })\n",
        "  print(f\"Estrategia: {estrategia}\")\n",
        "  print(f\"Accuracy: {acc:.4f}\")\n",
        "  print(f\"Recall: {rec:.4f}\")\n",
        "  print(f\"Precision: {prec:.4f}\")\n",
        "  print(f\"F1 Score: {f1_sc:.4f}\")\n",
        "  print()"
      ],
      "metadata": {
        "id": "ItnzozIq8i9b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Ejercicio - 1**"
      ],
      "metadata": {
        "id": "_mK6SXmx-m71"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **En este ejercicio deseamos obtener el umbral del desempeño mínimo que debiera alcanzar nuestro modelo, es decir, obtener el desempeño del modelo más simple (dummy). Consideraremos las siguientes políticas de la función DummyClassifier(): \"most_frequent\", \"prior, \"stratified\" y \"uniform\".**\n",
        "\n",
        "Recuerda revisar la documentación correspondiente:\n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.dummy.DummyClassifier.html"
      ],
      "metadata": {
        "id": "8Sqh3yly-qu4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Ejercicio 1a**\n",
        "\n",
        "#### **Para los casos \"most_frequent\" y \"prior\" observamos que se obtiene un \"UndefinedMetricWarning\" y nos dice que la métrica Precision no está bien definida (\"ill-defined\") ¿Qué significa este aviso? ¿Y si usamos la fórmula de Precision, qué nos resultaría?**\n",
        "\n",
        "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "\n",
        "Incluye aquí tus comentarios.\n",
        "\n",
        "None\n",
        "\n",
        "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++"
      ],
      "metadata": {
        "id": "n-c3u1tIAq5f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Ejercicio 1b**\n",
        "\n",
        "#### **Supongamos que la métrica que vamos a estar monitoreando es el \"F1-score\". Si esta fuera nuestra decisión y considerando los valores numéricos obtenidos en la celda anterior, ¿cuál de las cuatro políticas (\"most_frequent\", \"prior, \"stratified\", \"uniform\") recomendarías utilizar para obtener el desempeño mínimo que debiera tener nuestro mejor modelo que vamos a construir con RandomForest? Y por lo tanto, ¿cuál sería este valor mínimo? Justifica tu decisión.**\n",
        "\n",
        "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "\n",
        "Incluye aquí tus comentarios.\n",
        "\n",
        "None\n",
        "\n",
        "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++"
      ],
      "metadata": {
        "id": "oNyEqgq3Ph4n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Ejercicio - 2:**"
      ],
      "metadata": {
        "id": "Ee9SfRM5UXAa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* #### **En lo que resta de esta primera parte de la Actividad, supondremos que la métrica F1-score es la que nos interesa monitorear.**\n",
        "\n",
        "* #### **Así, a continuación deberás encontrar la mejor configuración del modelo Bosque Aleatorio que te resulte en la mejor métrica F1-score con respecto a la clase positiva 1.**\n",
        "\n",
        "* #### **Además, el modelo no debe estar sub-entrenado o sobre-entrenado con respecto a esta métrica F1-score.**\n",
        "\n",
        "* #### **Deberas decidir si se requiere incluir alguna técnica de sub-mestreo y/o sobre-muestro.**\n",
        "\n",
        "* #### **Incluye los hiperparámetros que consideres adecuados, pero recuerda que si incluyes demasiados, el tiempo de entrenamiento se incrementa.**\n",
        "\n",
        "\n",
        "Revisa la documentación correspondiente:\n",
        "\n",
        "* https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
        "\n",
        "* https://imbalanced-learn.org/stable/references/over_sampling.html\n",
        "\n",
        "* https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html"
      ],
      "metadata": {
        "id": "EdMskCNxaew7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ejercicio 2:\n",
        "\n",
        "\n",
        "# ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "# +++++++ INICIA SECCIÓN PARA INCLUIR TUS AJUSTES ++++++++++++++++++\n",
        "\n",
        "# Incluyo algunos ejemplos, pero puedes incluir más si lo deseas, revisa\n",
        "# la documentación correspondiente.\n",
        "\n",
        "# Definimos nuestro pipeline:\n",
        "pipeline = Pipeline([\n",
        "    #('smote', SMOTE()),  # Descomenta si deseas usar técnica de balanceo\n",
        "    ('model', RandomForestClassifier(random_state=17))\n",
        "])\n",
        "\n",
        "# Definimos los posibles valores para la búsqueda de malla.\n",
        "# El total de opciones a buscar en esta malla se obtiene con el producto\n",
        "# de la cantidad de casos de cada hiperparámetro.\n",
        "# Observa la diferencia entre el guión bajo doble y el sencillo.\n",
        "param_grid = {\n",
        "    'smote__k_neighbors': [5,7],  # Descomenta para usar hiperparámetros de la técnica de balanceo.\n",
        "    'model__n_estimators': [50,100],  # Hiperparámetros del modelo ...\n",
        "    #'model__max_depth': [],\n",
        "    #'model__min_samples_split': [],\n",
        "    #'model__class_weight':[]\n",
        "\n",
        "    # agregar todos los demás hiperparámetros que desees...\n",
        "}\n",
        "\n",
        "\n",
        "# Utilizaremos Validación Cruzada Estratificada:\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=17)\n",
        "\n",
        "# Aquí definimos la métrica a utilizar, en nuestro caso, F1-score:\n",
        "scorer = make_scorer(f1_score, average='binary', pos_label=1) # Esta línea no la modifiques.\n",
        "\n",
        "# Conjuntamos todo en la búsqueda de malla GridSearch:\n",
        "grid_search = RandomizedSearchCV(\n",
        "    estimator=pipeline,\n",
        "    param_distributions=param_grid,\n",
        "    n_iter=None,   # Aquí indicas el número de opciones del param_grid en los que harás la búsqueda.\n",
        "    cv=cv,\n",
        "    scoring=scorer,\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# +++++++++++++ TERMINA SECCIÓN PARA REALIZAR AJUSTES +++++++++++++++\n",
        "# +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "\n",
        "\n",
        "\n",
        "# Hacemos el ajuste del modelo con los datos de entrenamiento:\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Y evaluamos con el mejor  conjunto de prueba\n",
        "#best_model = grid_search.best_estimator_\n",
        "#y_pred = best_model.predict(X_test)\n",
        "\n",
        "best_params = grid_search.best_params_\n",
        "print(f\"\\nMejores parámetros encontrados:\\n {best_params}\\n\\n\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# **************************************************************************\n",
        "# Gráfico de curvas de aprendizaje del mejor modelo.\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# Definimos tamaños de entrenamiento relativos al conjunto de entrenamiento:\n",
        "train_sizes = np.linspace(0.1, 1.0, 10)\n",
        "\n",
        "# Calculamos curvas de aprendizaje con cross-validation:\n",
        "train_sizes, train_scores, valid_scores = learning_curve(\n",
        "    estimator=best_model,     # Usamos el mejor modelo encontrado\n",
        "    X=X_train,\n",
        "    y=y_train,\n",
        "    train_sizes=train_sizes,  # Tamaños de entrenamiento a evaluar\n",
        "    cv=5,\n",
        "    scoring='f1',             # Métrica a evaluar, en nuetro caso F1-score\n",
        "    n_jobs=-1,                # Usar todos los núcleos disponibles\n",
        "    random_state=17\n",
        ")\n",
        "\n",
        "# Calculamos medias y desviaciones estándar:\n",
        "train_mean = np.mean(train_scores, axis=1)\n",
        "train_std = np.std(train_scores, axis=1)\n",
        "valid_mean = np.mean(valid_scores, axis=1)\n",
        "valid_std = np.std(valid_scores, axis=1)\n",
        "\n",
        "\n",
        "# Área sombreada en el gráfico para la desviación estándar:\n",
        "plt.figure(figsize=(6, 5))\n",
        "plt.fill_between(train_sizes, train_mean - train_std,\n",
        "                 train_mean + train_std, alpha=0.1, color='blue')\n",
        "plt.fill_between(train_sizes, valid_mean - valid_std,\n",
        "                 valid_mean + valid_std, alpha=0.1, color='orange')\n",
        "\n",
        "# Grafcamos el polígono de las medias:\n",
        "plt.plot(train_sizes, train_mean, 'o-', color='blue', label='F1-score de Entrenamiento')\n",
        "plt.plot(train_sizes, valid_mean, 'o-', color='orange', label='F1-score de Validación (Cruzada)')\n",
        "\n",
        "\n",
        "plt.title(f'Curvas de Aprendizaje del mejor modelo')\n",
        "plt.xlabel('Tamaño del conjunto de entrenamiento')\n",
        "plt.ylabel('métrica F1-score')\n",
        "plt.grid(True)\n",
        "plt.legend(loc='lower right')\n",
        "#plt.ylim([0.8, 1.01])  # Puedes ajustar el rango del eje Y según tus datos\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hNv4Vz9EGx_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_search   # mejor configuración obtenida"
      ],
      "metadata": {
        "id": "d_0xMYipqpiH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Conjunto de Prueba**"
      ],
      "metadata": {
        "id": "f4GHJuyHuhYM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pasemos a predecir con el conjunto de Prueba (Test) una vez\n",
        "# que encontraste tu mejor modelo.\n",
        "\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "# Probabilidades de predicción para la clase 1\n",
        "y_proba = best_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Matriz de confusión:\n",
        "cm = confusion_matrix(y_test, y_pred, normalize='true')\n",
        "plt.figure(figsize=(3,3))\n",
        "sns.heatmap(cm, annot=True, fmt='.2g', cmap='Blues', cbar=False)   # en caso de enteros: fmt='d'\n",
        "plt.title('Matriz de Confusión')\n",
        "plt.xlabel('Predicción')\n",
        "plt.ylabel('Real')\n",
        "plt.xticks([0.5, 1.5], ['Clase 0', 'Clase 1'])\n",
        "plt.yticks([0.5, 1.5], ['Clase 0', 'Clase 1'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lhLYVImfClOq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reporte de clasificación estándar\n",
        "print(\"Reporte de Clasificación Estándar:\")\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "WmYt6w-yCoPT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Nuevo umbral de decisión con F1-score**"
      ],
      "metadata": {
        "id": "L6CuWELf7yYn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# En problemas desbalanceados, el umbral por defecto de 0.5 puede no ser el óptimo\n",
        "# para hacer las predicciones:\n",
        "# Si y_proba>0.5, entonces lo asignamos a la Clase_1, en otro caso, a la Clase_0.\n",
        "\n",
        "# Vamos a encontrar el umbral que maximiza el F1-score y determinar si sigue\n",
        "# siendo el valor por defecto.\n",
        "\n",
        "thresholds = np.arange(0.1, 0.9, 0.05)\n",
        "f1_scores = []\n",
        "\n",
        "for threshold in thresholds:\n",
        "    y_binary = (y_proba >= threshold).astype(int)\n",
        "    f1 = f1_score(y_test, y_binary)\n",
        "    f1_scores.append(f1)\n",
        "\n",
        "# Encontrar el mejor umbral\n",
        "best_threshold_idx = np.argmax(f1_scores)\n",
        "best_threshold = thresholds[best_threshold_idx]\n",
        "best_f1 = f1_scores[best_threshold_idx]\n",
        "\n",
        "plt.figure(figsize=(8,4))\n",
        "plt.plot(thresholds, f1_scores, 'o-', color='purple')\n",
        "plt.axvline(x=best_threshold, color='r', linestyle='--',\n",
        "            label=f'Umbral óptimo = {best_threshold:.2f}, F1 = {best_f1:.3f}')\n",
        "plt.axvline(x=0.5, color='g', linestyle='--',\n",
        "            label=f'Umbral predeterminado = 0.5, F1 = {f1_score(y_test, (y_proba >= 0.5).astype(int)):.3f}')\n",
        "plt.title('F1-score vs Umbral de Decisión')\n",
        "plt.xlabel('Umbral')\n",
        "plt.ylabel('F1-score')\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "shABDCkaC98a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluar el modelo con el umbral óptimo\n",
        "y_pred_optimal = (y_proba >= best_threshold).astype(int)\n",
        "print(\"\\nResultados con umbral óptimo:\")\n",
        "print(classification_report(y_test, y_pred_optimal))"
      ],
      "metadata": {
        "id": "lgEmaWsRDBMr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Matriz de confusión con umbral óptimo\n",
        "cm_optimal = confusion_matrix(y_test, y_pred_optimal, normalize='true')\n",
        "plt.figure(figsize=(3,3))\n",
        "sns.heatmap(cm_optimal, annot=True, fmt='.2g', cmap='Blues', cbar=False)\n",
        "plt.title(f'Matriz de Confusión (Umbral = {best_threshold:.2f})')\n",
        "plt.xlabel('Predicción')\n",
        "plt.ylabel('Real')\n",
        "plt.xticks([0.5, 1.5], ['Clase 0', 'Clase 1'])\n",
        "plt.yticks([0.5, 1.5], ['Clase 0', 'Clase 1'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "H4Q86k_ODDJU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Ejercicio - 3**"
      ],
      "metadata": {
        "id": "npsG0Br_756s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Con base a los resultados obtenidos responde los siguientes incisos que ayuden a concluir esta primera parte de la actividad.**\n",
        "\n",
        "* **Ejercicio 3a: Comenta por qué el modelo final que obtuviste no está subentrenado, ni sobreentrenado.**\n",
        "\n",
        "\n",
        "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "\n",
        "Incluye aquí tus comentarios.\n",
        "\n",
        "None\n",
        "\n",
        "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "\n",
        "* **Ejercicio 3b: Comenta las diferencias (si las hay) que observas entre usar el umbral predeterminado 0.5 y el nuevo umbral.**\n",
        "\n",
        "\n",
        "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "\n",
        "Incluye aquí tus comentarios.\n",
        "\n",
        "None\n",
        "\n",
        "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "\n",
        "\n",
        "* **Ejercicio 3c: Comenta el impacto que viste al usar o no alguna técnica de submuestreo.**\n",
        "\n",
        "\n",
        "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "\n",
        "Incluye aquí tus comentarios.\n",
        "\n",
        "None\n",
        "\n",
        "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "\n",
        "\n",
        "* **Ejercicio 3d: incluye tus comentarios finales de esta primera parte de la actividad.**\n",
        "\n",
        "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "\n",
        "Incluye aquí tus comentarios.\n",
        "\n",
        "None\n",
        "\n",
        "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n"
      ],
      "metadata": {
        "id": "XEMqYuHV7-AU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PARTE - 2 - XGBoost - Regressor**"
      ],
      "metadata": {
        "id": "CLWCrmnpse89"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ver documentación para hiperparámetros del modelo:\n",
        "\n",
        "https://xgboost.readthedocs.io/en/latest/python/python_api.html#xgboost.XGBRegressor\n",
        "\n",
        "https://xgboost.readthedocs.io/en/stable/parameter.html"
      ],
      "metadata": {
        "id": "dPL4pQExqaYF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_validate\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_absolute_percentage_error\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.model_selection import learning_curve\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Semilla para reproducibilidad\n",
        "np.random.seed(17)"
      ],
      "metadata": {
        "id": "UXBwNYWAsuSs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generamos un dataset de regresión con 10,000 muestras y 20 características\n",
        "X, y = make_regression(n_samples=10_000,\n",
        "                       n_features=20,\n",
        "                       n_informative=15,\n",
        "                       n_targets=1,\n",
        "                       noise=100.,\n",
        "                       random_state=17)\n",
        "\n",
        "# Convertimos a DataFrame de Pandas:\n",
        "df = pd.DataFrame(X, columns=[f\"feat_{i}\" for i in range(X.shape[1])])\n",
        "df['target'] = y\n",
        "\n",
        "print(\"Forma del dataset:\", df.shape)\n"
      ],
      "metadata": {
        "id": "Cb_-4O02sxxz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe().T   # Observa que estos factores ya están en un rango análogo de -4 a 4, aprox."
      ],
      "metadata": {
        "id": "pmzbKdYJ-ThU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# División en Train vs Test (80% vs 20%)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=17)\n",
        "\n",
        "print(\"Tamaño de entrenamiento:\", X_train.shape)\n",
        "print(\"Tamaño de test:\", X_test.shape)"
      ],
      "metadata": {
        "id": "mawdVgZEs14t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Ejercicio - 4**"
      ],
      "metadata": {
        "id": "mSgbKTzTDh65"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Desempeño del modelo base (baseline)**\n",
        "\n",
        "#### **Las líneas de código de la siguiente celda son un análisis que nos ayudarán posteriormente a determinar si el modelo que obtengamos estará o no subentrenado.**\n",
        "\n",
        "* **Ejercicio 4a: Explica con tus palabras de manera clara lo que hacen estas líneas de código para poder obtener de ahí el modelo base (baseline) de un modelo de regresión.**\n",
        "\n",
        "\n",
        "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "\n",
        "Incluye aquí tus comentarios.\n",
        "\n",
        "None\n",
        "\n",
        "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "\n",
        "\n",
        "\n",
        "* **Ejercicio 4b: Explica el significado de los valores numéricos mostrados: Valor_1 y Valor_2.**\n",
        "\n",
        "\n",
        "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "\n",
        "Incluye aquí tus comentarios.\n",
        "\n",
        "None\n",
        "\n",
        "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++"
      ],
      "metadata": {
        "id": "IZIFFGh9_IBv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Xt, Xv, yt, yv = train_test_split(X_train, y_train, test_size=0.2, random_state=17)\n",
        "yt_mean = np.mean(yt)\n",
        "y_pred_baseline = np.full(shape=yv.shape, fill_value=yt_mean)\n",
        "rmse_baseline = np.sqrt(mean_squared_error(yv, y_pred_baseline))\n",
        "\n",
        "print(f\"Valor_1-Ejercicio-4b: {yt_mean:.4f}\\n\")\n",
        "print(f\"Valor_2-Ejercicio-4b: {rmse_baseline:.4f}\")"
      ],
      "metadata": {
        "id": "lOJRJ4ASwl42"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Ejercicio - 5**"
      ],
      "metadata": {
        "id": "xTNI0fB5GzsO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* #### **Encuentra la mejor configuración del modelo XGBoost que te resulte con la métrica RMSE.**\n",
        "\n",
        "* #### **Además, el modelo no debe estar sub-entrenado o sobre-entrenado.**\n",
        "\n",
        "* #### **Incluye los hiperparámetros que consideres adecuados, pero recuerda que si incluyes demasiados, el tiempo de entrenamiento se incrementa.**"
      ],
      "metadata": {
        "id": "RjrLzN-KG3w2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "# +++++++ INICIA SECCIÓN PARA INCLUIR TUS AJUSTES ++++++++++++++++++\n",
        "\n",
        "# Instanciamos el modelo base:\n",
        "model = XGBRegressor(random_state=17, n_jobs=-1)\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200],\n",
        "    # Incluye aquí todos los casos que desees buscar en la malla.\n",
        "}\n",
        "\n",
        "# Métricas de regresión a evaluar:\n",
        "scoring = {\n",
        "    'MAE': 'neg_mean_absolute_error',\n",
        "    'RMSE': 'neg_root_mean_squared_error',\n",
        "    'R2': 'r2',\n",
        "    'MAPE': 'neg_mean_absolute_percentage_error'\n",
        "}\n",
        "\n",
        "\n",
        "# Configuración del grid search aleatorio:\n",
        "grid_search = RandomizedSearchCV(\n",
        "    estimator=model,\n",
        "    param_distributions=param_grid,\n",
        "    n_iter=None,         # Indica la cantidad de casos a buscar en la malla.\n",
        "    scoring=scoring,\n",
        "    refit='RMSE',      # Selecciona el mejor modelo según esta métrica RMSE.\n",
        "    cv=5,\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# +++++++++++++ TERMINA SECCIÓN PARA REALIZAR AJUSTES +++++++++++++++\n",
        "# +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "\n",
        "\n",
        "\n",
        "# Pasamos al entrenamiento del modelo:\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "# **********************************************************************\n",
        "# Medimos el desempeño del modelo con respecto al modelo base (baseline):\n",
        "rmse_xgb = -grid_search.best_score_\n",
        "\n",
        "print(f\"\\nRMSE del modelo XGBoost: {rmse_xgb:.4f}\\n\")\n",
        "print(f\"Resultado-para-el-Ejercicio-6b: {(rmse_baseline - rmse_xgb) / rmse_baseline * 100:.1f}%\\n\")\n",
        "\n",
        "\n",
        "\n",
        "# ***********************************************************************\n",
        "# Visualizamos el aprendizaje del mejor modelo:\n",
        "# Usamos el mejor modelo encontrado por GridSearchCV\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# Definimos los tamaños de entrenamiento a evaluar\n",
        "train_sizes = np.linspace(0.1, 1.0, 10)\n",
        "\n",
        "# Calcular las curvas de aprendizaje usando RMSE\n",
        "train_sizes, train_scores, test_scores = learning_curve(\n",
        "    estimator=best_model,\n",
        "    X=X_train,\n",
        "    y=y_train,\n",
        "    train_sizes=train_sizes,\n",
        "    cv=5,\n",
        "    scoring='neg_root_mean_squared_error',\n",
        "    n_jobs=-1,\n",
        "    shuffle=True,\n",
        "    random_state=17\n",
        ")\n",
        "\n",
        "# Convertimos los puntajes negativos de RMSE a positivos\n",
        "train_rmse = -train_scores.mean(axis=1)\n",
        "test_rmse = -test_scores.mean(axis=1)\n",
        "\n",
        "plt.figure(figsize=(8,4))\n",
        "plt.plot(train_sizes, train_rmse, label='Entrenamiento (RMSE)', color='blue')\n",
        "plt.plot(train_sizes, test_rmse, label='Validación (RMSE)', color='red', linestyle='--')\n",
        "plt.title('Curva de Aprendizaje - RMSE')\n",
        "plt.xlabel('Tamaño del conjunto de entrenamiento')\n",
        "plt.ylabel('RMSE')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "q5bgO_FJs81Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Obtenemos finalmente información con respecto al conjunto de Prueba:**"
      ],
      "metadata": {
        "id": "6vlVlTOCZ6KP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "grid_search   # configuración del mejor modelo encontrado"
      ],
      "metadata": {
        "id": "Na4u4JwEWW3l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicciones en el conjunto de Prueba (Test) con el mejor modelo encontrado:\n",
        "y_pred = grid_search.predict(X_test)\n",
        "\n",
        "# Calculamos los valores de las métricas:\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
        "\n",
        "print(\"\\nResultados-para-el-Ejercicio-6c:\")\n",
        "print(\"\\nMétricas en Test:\")\n",
        "print(f\"MAE: {mae:.4f}\")\n",
        "print(f\"RMSE: {rmse:.4f}\")\n",
        "print(f\"R²: {r2:.4f}\")\n",
        "print(f\"MAPE: {mape:.2f}%\")"
      ],
      "metadata": {
        "id": "gltpxoh_vACA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gráfico de dispersión entre valores reales y predichos\n",
        "plt.figure(figsize=(8,4))\n",
        "sns.scatterplot(x=y_test, y=y_pred, alpha=0.6)\n",
        "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
        "plt.xlabel('Valores reales')\n",
        "plt.ylabel('Predicciones')\n",
        "plt.title('Valores reales vs Predicciones')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "WvmBeW72v6F_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Ejercicio - 6**"
      ],
      "metadata": {
        "id": "ZOAL8pHKbVNr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Con base a los resultados obtenidos responde los siguientes incisos que ayuden a concluir esta segunda parte de la actividad.**\n",
        "\n",
        "* **Ejercicio 6a: Comenta por qué el modelo final que obtuviste no está subentrenado, ni sobreentrenado.**\n",
        "\n",
        "\n",
        "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "\n",
        "Incluye aquí tus comentarios.\n",
        "\n",
        "None\n",
        "\n",
        "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "\n",
        "\n",
        "* **Ejercicio 6b: Indica cómo interpretas el valor obtenido en \"Resultado-para-el-Ejercicio-6b\".**\n",
        "\n",
        "\n",
        "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "\n",
        "Incluye aquí tus comentarios.\n",
        "\n",
        "None\n",
        "\n",
        "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "\n",
        "\n",
        "\n",
        "* **Ejercicio 6c: Indica cómo interpretas cada uno de los resultados que obtuviste en \"Resultados-para-el-Ejercicio-6c\".**\n",
        "\n",
        "\n",
        "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "\n",
        "Incluye aquí tus comentarios.\n",
        "\n",
        "None\n",
        "\n",
        "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "\n",
        "* **Ejercicio 3d: Incluye tus comentarios finales de esta segunda parte de la actividad.**\n",
        "\n",
        "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "\n",
        "Incluye aquí tus comentarios.\n",
        "\n",
        "None\n",
        "\n",
        "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++"
      ],
      "metadata": {
        "id": "W6mKKg8AbQn3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Ejercicio - 7**"
      ],
      "metadata": {
        "id": "UrxY-00hdqOQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Ejercicio 7: incluye tus comentarios finales de esta actividad.**\n",
        "\n",
        "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "\n",
        "Incluye aquí tus comentarios.\n",
        "\n",
        "None\n",
        "\n",
        "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++"
      ],
      "metadata": {
        "id": "HfBtXn6GdxYK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Fin de la Actividad de modelos basados en áboles**"
      ],
      "metadata": {
        "id": "phuZNBsjeDQh"
      }
    }
  ]
}