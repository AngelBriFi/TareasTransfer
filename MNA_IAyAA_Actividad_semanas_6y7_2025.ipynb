{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "gOoOtosZ4bzA",
        "wLK5tyC0afDk",
        "qmprVkJ_u56j",
        "hEvpbd7kBM7p",
        "a4Ka79ZTyM0_",
        "JC30wsrhG8f4",
        "HKwEq8z-zS7G",
        "_MSXjy6i8qRD"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Maestría en Inteligencia Artificial Aplicada**\n",
        "\n",
        "## **Curso: Inteligencia Artificial y Aprendizaje Automático**\n",
        "\n",
        "### Tecnológico de Monterrey\n",
        "\n",
        "### Prof Luis Eduardo Falcón Morales\n",
        "\n",
        "## Adtividad de Semanas 6 y 7\n",
        "\n",
        "### **Campañas publicitarias en redes sociales - Modelos de Regresión**\n"
      ],
      "metadata": {
        "id": "cCgXoRxlVFi0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### **Nombres y Matrículas:**\n",
        "\n",
        "\n",
        "*   Elemento de lista\n",
        "*   Elemento de lista\n",
        "*   Elemento de lista\n"
      ],
      "metadata": {
        "id": "P2p9VQXDtFnZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Trabajaremos con el archivo \"dataset_Facebook.csv\" que encuentras en la siguiente liga:**\n",
        "\n",
        "https://archive.ics.uci.edu/dataset/368/facebook+metrics\n",
        "\n",
        "### **Estos datos están asociados al siguiente artículo de Moro et.al. de ELSEVIER, que deberás descargar para contestar varias de las preguntas de esta actividad (el acceso es sin costo alguno):**\n",
        "\n",
        "https://www.semanticscholar.org/paper/Predicting-social-media-performance-metrics-and-of-Moro-Rita/dec55692590820754b53c916e29bb2b42c0e5104\n"
      ],
      "metadata": {
        "id": "EZ_5sfaamvHY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **NOTA: No modifiques el código, salvo en las partes que se te indica.**"
      ],
      "metadata": {
        "id": "gOoOtosZ4bzA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Puedes incluir más librerías, de ser necesario:\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, OrdinalEncoder\n",
        "\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.svm import SVR\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import RepeatedKFold\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import learning_curve\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "np.random.seed(0)\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "9MZs9gKJ1fWZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Ejercicio 1**\n"
      ],
      "metadata": {
        "id": "wLK5tyC0afDk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **De acuerdo al artículo de Moro et.al. de ELSEVIER, contesta las siguientes preguntas:**\n",
        "\n",
        "*   **a. ¿Cuál es el objetivo del problema que se plantea en el artículo?**\n"
      ],
      "metadata": {
        "id": "8pcpweI8aie8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ++++++++ Inicia la sección de agregar texto: +++++++++++\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### ++++++++ Termina la sección de agregar texto. +++++++++++"
      ],
      "metadata": {
        "id": "WIqvDWS4tFF2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "*   **b. Describe a continuación el significado de cada una de las 8 variables con la cuales trabajaremos, de acuerdo a la información de las Tablas 2 y 3 del artículo de Moro et.al.**"
      ],
      "metadata": {
        "id": "DbSEBatds8Vu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ++++++++ Inicia la sección de agregar texto: +++++++++++\n",
        "\n",
        "\n",
        "*   Elemento de lista\n",
        "*   Elemento de lista\n",
        "\n",
        "etc ...\n",
        "\n",
        "\n",
        "### ++++++++ Termina la sección de agregar texto. +++++++++++"
      ],
      "metadata": {
        "id": "tHWhAUezdc-E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **En esta actividad trabajarás solamente con el ajuste de modelos, por lo que la parte de procesamiento no la debes modificar. Solo haremos unos pequeños ajustes.**"
      ],
      "metadata": {
        "id": "N7aMmfvpWS2b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargamos los datos del archivo:\n",
        "\n",
        "data = pd.read_csv('dataset_Facebook.csv', sep=';', header='infer')\n",
        "print('Total de registros y variables:',data.shape)\n",
        "data.head(3).T"
      ],
      "metadata": {
        "id": "G8fYoeHruPu5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Ejercicio 2**"
      ],
      "metadata": {
        "id": "qmprVkJ_u56j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Variables relacionadas con el tiempo**\n",
        "\n",
        "### **Recordemos que las variables relacionadas con información del tiempo (meses, semanas, horas) pueden tratarse como variables categóricas o numéricas, dependiendo del contexto. En nuestro caso las variables mes, día de la semana y hora en que se puso el post, podríamos considerarlas como variables categóricas ordinales o bien como nominales. Sin embargo, para recordar cómo se transforman este tipo de variables en numéricas cíclicas, las transformarás a continuación.**\n",
        "\n",
        "### **En la Tabla 3 del artículo de ELSEVIER nos comentan que la variable Post_hour está etiquetada de 0 a 23, por lo que las 24 horas serían las 0 horas, es decir tiene un comportamiento cíclico de 24 horas, que en términos matemáticos se dice que es una variable cíclica módulo 24. Así, las 24 horas será equivalente a las 0 horas. De manera análoga se procede con las variables del mes y el día de la semana.**\n",
        "\n",
        "### **Se comenta en la Tabla 3 del artículo que las variables en relación al mes y día de la semana en que se publicó el post, que son los nombres de los meses y los días de la semana. Sin embargo, en realidad están capturadas como numéricas del 1 al 12 y del 1 al 7, respectivamente.**\n",
        "\n",
        "### **La manera de transformar una variable T cíclica módulo M, es sustituyendo la columna original de la variable T por las siguientes dos columnas. Estas transformaciones están dentro de lo que se llama ingeniería de características (feature engineering):**\n",
        "\n",
        "$Tsin = sin(2*\\pi*T/M)$\n",
        "\n",
        "$Tcos = cos(2*\\pi*T/M)$"
      ],
      "metadata": {
        "id": "flldXIo3uX6A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **NOTA: En las siguientes celdas donde se indica None, podrás agregar las líneas de código que consideres necesarias.**"
      ],
      "metadata": {
        "id": "joCe2SKLwl5m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ejercicio 2a:\n",
        "\n",
        "# Define las dos nuevas variables cíclicas, \"hora_sin\" y \"hora_cos\" a partir\n",
        "# de la variable \"Post Hour\" y de acuerdo a como se indicó previamente:\n",
        "\n",
        "\n",
        "# ++++++++++++++ Incluye aquí tu código ++++++++++++++++++++++++++++++\n",
        "\n",
        "hora_sin = None\n",
        "hora_cos = None\n",
        "\n",
        "\n",
        "\n",
        "# +++++++++++++ Tesrmina sección de agregar código +++++++++++++++++++++"
      ],
      "metadata": {
        "id": "-HegyBexvaA8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ejercicio 2b:\n",
        "\n",
        "# Agrega estas dos nuevas variables al DataFrame de tus datos\n",
        "# y elimina la columna de la variable original \"Post Hour\":\n",
        "\n",
        "# ++++++++++++++ Incluye aquí tu código ++++++++++++++++++++++++++++++\n",
        "\n",
        "None\n",
        "\n",
        "\n",
        "\n",
        "# +++++++++++++ Termina sección de agregar código +++++++++++++++++++++\n"
      ],
      "metadata": {
        "id": "_q9bj6tZwi7d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ejercicio 2c.\n",
        "\n",
        "# Transforma de manera análoga la variable \"Post Month\"\n",
        "# agregando mes_sin, mes_cos y eliminando la original.\n",
        "\n",
        "\n",
        "# ++++++++++++++ Incluye aquí tu código ++++++++++++++++++++++++++++++\n",
        "\n",
        "mes_sin = None\n",
        "mes_cos = None\n",
        "\n",
        "\n",
        "\n",
        "# +++++++++++++ Tesrmina sección de agregar código +++++++++++++++++++++\n"
      ],
      "metadata": {
        "id": "Du0rPKhNnZk5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ejercicio 2d.\n",
        "\n",
        "# Transforma de manera análoga la variable \"Post Weekday\"\n",
        "# agregando dia_sin, dia_cos y eliminando la original.\n",
        "\n",
        "\n",
        "# ++++++++++++++ Incluye aquí tu código ++++++++++++++++++++++++++++++\n",
        "\n",
        "dia_sin = None\n",
        "dia_cos = None\n",
        "\n",
        "\n",
        "\n",
        "# +++++++++++++ Tesrmina sección de agregar código +++++++++++++++++++++\n"
      ],
      "metadata": {
        "id": "9SvwkhX6oi1D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Veamos lo que tenemos hasta el momento:\n",
        "data.head(3).T"
      ],
      "metadata": {
        "id": "xagfZfU-_PAz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# De las Tablas 2 y 3 del artículo de ELSEVIER seleccionamos las variables que\n",
        "# trabajaremos en esta Actividad, con el ajuste que acabamos de hacer:\n",
        "\n",
        "# Separamos los datos de entrada (ver Tabla 3 del artículo) y de la variable de salida (ver Tabla 2):\n",
        "X = data[['Page total likes', 'Type', 'Category', 'Paid',\n",
        "          'mes_sin', 'mes_cos', 'dia_sin', 'dia_cos', 'hora_sin', 'hora_cos']]\n",
        "y = data[['Lifetime Post Consumers']]   # Hay 12 variables de salida, pero solo trabajaremos con una de las\n",
        "                                        # que se consideró más importante en el artículo de ELSEVIER.\n",
        "\n",
        "\n",
        "# En esta acrividad trataremos de comparar resultados con lo realizado en\n",
        "# el artículo de Moro et.al., por lo que solo particionaremos en Train y Test.\n",
        "# Particionamos en Train y Test en 80-20:\n",
        "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, train_size=0.8, shuffle=True, random_state=5)\n",
        "\n",
        "print('Train:', Xtrain.shape, ytrain.shape)\n",
        "print('Test:', Xtest.shape, ytest.shape)\n"
      ],
      "metadata": {
        "id": "N6m_XqcQnCHP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Xtrain.describe(include='all').T   # Veamos alguna descripción como datos numéricos del conjunto de entrenamiento.\n",
        "                                   # En particular, las desviaciones estándar (std) desplegadas son las muestrales."
      ],
      "metadata": {
        "id": "7oog40NRzRSW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Ajuste variable categórica en Pipeline**\n",
        "\n",
        "#### **Veamos un ejemplo de cómo ajustar una variable categórica en la cual uno de sus niveles no tiene suficiente información y que se transforme evitando el filtrado de información. Para ello se deberán reagruparemos los niveles más pequeños hasta obtener un 5% de información.**"
      ],
      "metadata": {
        "id": "PLNnZzcczZzv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtengamos las etiquetas únicas de data['Type'] ordenadas de mayor a menor frecuencia:\n",
        "Xtrain['Type'].unique()"
      ],
      "metadata": {
        "id": "bAIeoERKzY7E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Xtrain['Type'].value_counts(normalize=True)  # Siguiendo la política de que cada nivel de una variable tenga\n",
        "                                             # al menos el 5% de información, agruparemos los casos \"Link\"\n",
        "                                             # y \"Video\" en un nuevo nivel que podría interpretarse como \"Otros\"."
      ],
      "metadata": {
        "id": "lXg9rSO8zxr6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Para ello usaremos la siguiente Clase, que ayude a cuidar el filtrado de información durante el proceso de entrenamiento, en particular, al aplicar validación cruzada.**"
      ],
      "metadata": {
        "id": "yO4REeboAZ42"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformador personalizado para agrupar categorías poco frecuentes\n",
        "# en la variable \"Type\", a saber, \"Link\" y \"Video\".\n",
        "# Puedes posteriormente ajustar la clase para que de manera automática\n",
        "# se detecte que cada nivel tiene al menos un porcentaje de umbral determinado.\n",
        "\n",
        "class TypeGrouper(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self):\n",
        "        self.groups_to_replace = ['Link','Video']\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        X_copy = X.copy()\n",
        "        if not isinstance(X_copy, pd.DataFrame):\n",
        "            X_copy = pd.DataFrame(X_copy, columns=['Type'])\n",
        "\n",
        "        X_copy.loc[X_copy['Type'].isin(self.groups_to_replace), 'Type'] = 'Otros'\n",
        "        return X_copy\n"
      ],
      "metadata": {
        "id": "8qmVHp96qcAg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Ejercicio 3**"
      ],
      "metadata": {
        "id": "hEvpbd7kBM7p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Utiliza un LLM (indica cuál o cuáles usastes) para explicar cada línea de código de la celda anterior.**"
      ],
      "metadata": {
        "id": "UDgEVbfhBOTh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ++++++++ Inicia la sección de agregar texto: +++++++++++\n",
        "\n",
        "\n",
        "*   Elemento de lista\n",
        "*   Elemento de lista\n",
        "\n",
        "etc ...\n",
        "\n",
        "\n",
        "### ++++++++ Termina la sección de agregar texto. +++++++++++"
      ],
      "metadata": {
        "id": "xLNWRgygBx__"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Transformación en la Variable de Salida**\n",
        "\n"
      ],
      "metadata": {
        "id": "VbrYu10q0lUa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Histograma que muestra un claro sesgo positivo en la variable objetivo:\n",
        "ytrain.hist();"
      ],
      "metadata": {
        "id": "k-gb_Jwa0_6W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ytrainlog = np.log(ytrain)   # Recordemos que nuestra variable de salida en un problema\n",
        "ytrainlog.hist();            # de Regresión se recomienda que esté aproximadamente\n",
        "                             # acampanada, por lo que la ajustaremos con el logaritmo\n",
        "                             # natural como primera aproximación."
      ],
      "metadata": {
        "id": "L9BvLilz1EfC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Para una primera aproximación, podemos decir que se ajusta de manera aceptable\n",
        "# la distribución con logaritmo a una acampanada.\n",
        "# Procedemos entonces de la misma manera con Test:\n",
        "\n",
        "ytestlog = np.log(ytest)"
      ],
      "metadata": {
        "id": "B9Zm5VeA1EJK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ytestlog.describe().T  # información de la variable objetivo transformada."
      ],
      "metadata": {
        "id": "Cni8tcC_y_36"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Pipeline de transformaciones**"
      ],
      "metadata": {
        "id": "EOytV50MCpu7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Aplicaremos lo mínimo de transformaciones.\n",
        "# Las nuevas variables _sin y _cos ya quedaron escaladas entre -1 y +1, por\n",
        "# lo que podemos dejarlas así y solamente cuidar sus posibles datos perdidos\n",
        "# en datos futuros.\n",
        "\n",
        "num_pipe = Pipeline(steps = [('numImp', SimpleImputer(strategy='median')),\n",
        "                             ('scaler', MinMaxScaler())\n",
        "                             ])\n",
        "num_pipe_nombres = ['Page total likes']\n",
        "\n",
        "\n",
        "# Transformación del factor categórico de entrada \"Type\":\n",
        "catMap_pipe = Pipeline(steps = [('typeMap', Pipeline([('grouper', TypeGrouper()),\n",
        "                                                      ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
        "                                                      ]))])\n",
        "catMap_pipe_nombres = ['Type']\n",
        "\n",
        "\n",
        "# Las nominales las transformamos con One-Hot-Encoder:\n",
        "nom_pipe = Pipeline(steps = [('NomImp', SimpleImputer(strategy='most_frequent')),\n",
        "                             ('ohe', OneHotEncoder(drop='first',\n",
        "                                                   handle_unknown='ignore',\n",
        "                                                   ))])\n",
        "nom_pipe_nombres = ['Category', 'Paid']\n",
        "\n",
        "\n",
        "# Variables numéricas cíclicas:\n",
        "mes_pipe = Pipeline(steps = [('MesImp', SimpleImputer(strategy='mean'))])\n",
        "mes_pipe_nombres = ['mes_sin', 'mes_cos']\n",
        "\n",
        "dia_pipe = Pipeline(steps = [('DiaImp', SimpleImputer(strategy='mean'))])\n",
        "dia_pipe_nombres = ['dia_sin', 'dia_cos']\n",
        "\n",
        "hora_pipe = Pipeline(steps = [('HoraImp', SimpleImputer(strategy='mean'))])\n",
        "hora_pipe_nombres = ['hora_sin', 'hora_cos']\n",
        "\n",
        "\n",
        "# Conjuntamos las transformaciones:\n",
        "columnasTransformer = ColumnTransformer(transformers = [('numpow', num_pipe, num_pipe_nombres),\n",
        "                                                        ('catmap', catMap_pipe, catMap_pipe_nombres),\n",
        "                                                        ('catNom', nom_pipe, nom_pipe_nombres),\n",
        "                                                        ('mes', mes_pipe, mes_pipe_nombres),\n",
        "                                                        ('dia', dia_pipe, dia_pipe_nombres),\n",
        "                                                        ('hora', hora_pipe, hora_pipe_nombres)\n",
        "                                                        ],\n",
        "                                        remainder='passthrough')\n"
      ],
      "metadata": {
        "id": "XGjwO1zq1JBS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Solo para saber la nueva cantidad de columnas que tendremos\n",
        "# después de las trasnformaciones:\n",
        "XtrainT = columnasTransformer.fit_transform(Xtrain)  # Ajustamos con Train...\n",
        "print('Variables de entrada original:', Xtrain.shape)\n",
        "print('Variables de entrada transformadas:', XtrainT.shape)"
      ],
      "metadata": {
        "id": "sKbcQOHY3msP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Modelo Base (Baseline)**"
      ],
      "metadata": {
        "id": "VrK6xcSUyriz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Variable objetivo con Log:\n",
        "y_pred_baseline = np.full_like(ytestlog, fill_value=ytrainlog.mean())\n",
        "\n",
        "# RMSE del baseline\n",
        "rmse_baseline = mean_squared_error(ytestlog, y_pred_baseline)\n",
        "print(f\"MSE Baseline (promedio) con Logaritmo: {rmse_baseline:.2f}\")"
      ],
      "metadata": {
        "id": "882xKf_EyeI9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Ejercicio 4**\n"
      ],
      "metadata": {
        "id": "a4Ka79ZTyM0_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ejercicio 4a.\n",
        "\n",
        "# Al ejecutar las siguientes líneas de código determina si el modelo de\n",
        "# Bosque Aleatorio con sus valores de hiperparámetros predeterminadas está\n",
        "# Subentrenado o Sobreentrenado. De ser así, busca los valores de sus\n",
        "# hiperparámetros que consideres más adecuados para que ya no\n",
        "# esté sub-o-sobreentrenado:\n",
        "\n",
        "\n",
        "# ++++++++++++++ Incluye aquí tu código ++++++++++++++++++++++++++++++\n",
        "\n",
        "\n",
        "elmodelo_RF = RandomForestRegressor(random_state=1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# +++++++++++++ Tesrmina sección de agregar código +++++++++++++++++++++\n",
        "\n",
        "\n",
        "\n",
        "mipipe = Pipeline(steps=[('ct',columnasTransformer),('m', elmodelo_RF)])\n",
        "\n",
        "train_sizes, train_scores, val_scores = learning_curve(estimator=mipipe,\n",
        "                                                        X=Xtrain,\n",
        "                                                        y=np.ravel(ytrainlog),\n",
        "                                                        cv=5,\n",
        "                                                        train_sizes= np.linspace(0.1, 1.0, 10),\n",
        "                                                        scoring= 'neg_mean_squared_error',  # error MSE\n",
        "                                                        n_jobs=-1)\n",
        "\n",
        "\n",
        "\n",
        "# Calculamos los promedios y desviación estándar de entrenamiento para MSE.\n",
        "# El negativo es porque sklearn nos devuelve en realidad el negativo del error\n",
        "# cuadrático medio MSE.\n",
        "\n",
        "mse_train_scores = -train_scores\n",
        "mse_val_scores = -val_scores\n",
        "\n",
        "train_mean = np.mean(mse_train_scores, axis=1)\n",
        "train_mse = np.std(mse_train_scores, axis=1, ddof=1)\n",
        "val_mean = np.mean(mse_val_scores, axis=1)\n",
        "val_mse = np.std(mse_val_scores, axis=1, ddof=1)\n",
        "\n",
        "\n",
        "plt.plot(train_sizes, train_mean, color='blue', marker='o', markersize=5, label='Training MSE')\n",
        "plt.fill_between(train_sizes, train_mean + train_mse, train_mean - train_mse, alpha=0.15, color='blue')\n",
        "\n",
        "plt.plot(train_sizes, val_mean, color='green', marker='+', markersize=5, linestyle='--', label='Validation MSE')\n",
        "plt.fill_between(train_sizes, val_mean + val_mse, val_mean - val_mse, alpha=0.15, color='green')\n",
        "\n",
        "plt.title('Curvas de Aprendizaje (Learning Curves)')\n",
        "plt.xlabel('Tamaño de la muestra de entrenamiento')\n",
        "plt.ylabel('Error MSE')\n",
        "plt.grid()\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "oXpqwlS6lnSS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ejercicio 4b.\n",
        "\n",
        "# Una vez que verifiques que no está sobreentrenado o subentrenado el modelo,\n",
        "# podemos calcular el MSE del mejor ajuste con los datos de Prueba.\n",
        "# Incluye los valores de tus mejores hiperparámetros encontrados del RandomForest.\n",
        "\n",
        "# ++++++++++++++ Incluye aquí tus ajustes ++++++++++++++++++++++++++++++\n",
        "\n",
        "\n",
        "mejor_modelo_RF = RandomForestRegressor(random_state=1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# +++++++++++++ Tesrmina sección de realizar ajustes +++++++++++++++++++++\n",
        "\n",
        "\n",
        "mipipe = Pipeline(steps=[('ct',columnasTransformer),('m', mejor_modelo_RF)])\n",
        "mipipe.fit(pd.DataFrame(Xtrain, columns=Xtrain.columns), np.ravel(ytrainlog))\n",
        "yhattest_RF = mipipe.predict(Xtest)\n",
        "\n",
        "print('Error MSE(Test) de Random Forest: %.3f' % mean_squared_error(np.ravel(ytestlog), yhattest_RF))"
      ],
      "metadata": {
        "id": "5yEGf3-ft3cO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Ejercicio 5**"
      ],
      "metadata": {
        "id": "JC30wsrhG8f4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ejercicio 5:\n",
        "# Calcula ahora el error porcencual absoluto medio (MAPE por sus siglas en inglés)\n",
        "# del mejor modelo de Random Forest en el conjunto de Prueba (TEST).\n",
        "# Llamarle \"mape\" a dicha variable.\n",
        "\n",
        "\n",
        "# ++++++++++++++ Incluye aquí tus ajustes ++++++++++++++++++++++++++++++\n",
        "\n",
        "\n",
        "None\n",
        "\n",
        "\n",
        "\n",
        "# +++++++++++++ Tesrmina sección de realizar ajustes +++++++++++++++++++++\n",
        "\n",
        "\n",
        "# Imprimimos el resultado de MAPE en porcentaje:\n",
        "print(f\"MAPE: {mape:.2f}%\")\n"
      ],
      "metadata": {
        "id": "AcfJ_GTA4yIr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Ejercicio 6**"
      ],
      "metadata": {
        "id": "HKwEq8z-zS7G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Repite el mismo proceso del ejercicio con el modelo Bosque Aleatorio (Random Forest) para obtener los mejores modelos no subentrenados y no sobreentrenados, en cada uno de los siguientes casos:**\n",
        "\n",
        "*   **a. Extreme Gradient Boost XGBoost**\n",
        "*   **b. Máquina de Vector Soporte SVM**\n",
        "*   **c. Red Neuronal Perceptrón Multicapa MLP**"
      ],
      "metadata": {
        "id": "hLd2iTBMzZ93"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Incluye a continuación todas las celdas y líneas de código que consideres\n",
        "# necesarias para responder el Ejercicio 6a, 6b y 6c.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "None\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "uIuE5qYYvhkJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Ejercicio 7**"
      ],
      "metadata": {
        "id": "_MSXjy6i8qRD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Incluye tus conclusiones finales de la Actividad, en particular compara el resultado MAPE de tu mejor modelo del conjunto de Prueba (Test) con el resultado reportado en el artículo de Moro et.al en la sección de conclusiones.**"
      ],
      "metadata": {
        "id": "A01wHjjM0eNf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ++++++++ Inicia la sección de agregar texto: +++++++++++\n",
        "\n",
        "\n",
        "None\n",
        "\n",
        "\n",
        "### ++++++++ Termina la sección de agregar texto. +++++++++++"
      ],
      "metadata": {
        "id": "aeZrOQkU0x9X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Fin de la Actividad de la Semanas 6 y 7**"
      ],
      "metadata": {
        "id": "6r0YHMtI0ypO"
      }
    }
  ]
}